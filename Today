version: '3.3'

services:
  zookeeper:
    image: zookeeper:3.8.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/data
      - zookeeper_datalog:/datalog

  kafka:
    image: bitnami/kafka:3.3.2
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
    volumes:
      - kafka_data:/bitnami/kafka
    depends_on:
      - zookeeper

  mysql:
    image: mysql:8.0
    hostname: mysql
    container_name: mysql
    environment:
      - MYSQL_ROOT_PASSWORD=rootpassword
      - MYSQL_DATABASE=testdb
      - MYSQL_USER=testuser
      - MYSQL_PASSWORD=testpassword
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    command: --binlog-format=row --log-bin=mysql-bin --server-id=1

  jobmanager:
    image: flink:1.17.0-scala_2.12-java11
    hostname: jobmanager
    container_name: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
    ports:
      - "8081:8081"
      - "6123:6123"  # RPC
      - "6124:6124"  # Blob
    volumes:
      - ./conf:/opt/flink/conf
      - ./mysql-to-kafka-cdc.sql:/opt/flink/mysql-to-kafka-cdc.sql
      - ./jars:/opt/flink/lib
    command: >
      bash -c "
      chmod 755 /var/lib/apt/lists/partial;
      apt-get update && apt-get install -y netcat-openbsd;
      chown -R flink:flink /opt/flink/lib;
      su flink -c '/opt/flink/bin/jobmanager.sh start';
      while ! nc -z jobmanager 8081; do sleep 3; done;
      su flink -c '/opt/flink/bin/sql-client.sh -f /opt/flink/mysql-to-kafka-cdc.sql';
      tail -f /dev/null
      "

  taskmanager:
    image: flink:1.17.0-scala_2.12-java11
    hostname: taskmanager
    container_name: taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
      - TASK_MANAGER_NUMBER_OF_TASK_SLOTS=4
    ports:
      - "6122:6122"  # Data port
      - "6125:6125"  # Query port    

    volumes:
      - ./jars:/opt/flink/lib


    depends_on:
      - jobmanager
    command: >
      bash -c "
      /opt/flink/bin/taskmanager.sh start;
      tail -f /dev/null  # Keep container running
      "

networks:
  flink-network:
    driver: bridge


volumes:
  zookeeper_data:
  zookeeper_datalog:
  kafka_data:
  mysql_data:


initdb.sql:
-- Create test database if not exists
CREATE DATABASE IF NOT EXISTS testdb;
USE testdb;

-- Create a sample table
CREATE TABLE IF NOT EXISTS users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    username VARCHAR(100) NOT NULL,
    email VARCHAR(100) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

-- Insert some sample data
INSERT INTO users (username, email) VALUES
('user1', 'user1@example.com'),
('user2', 'user2@example.com'),
('user3', 'user3@example.com'),
('user4', 'user4@example.com'),
('user5', 'user5@example.com');

-- Create a sample table with more complex data
CREATE TABLE IF NOT EXISTS orders (
    order_id INT AUTO_INCREMENT PRIMARY KEY,
    user_id INT NOT NULL,
    product_name VARCHAR(100) NOT NULL,
    quantity INT NOT NULL,
    price DECIMAL(10, 2) NOT NULL,
    order_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- Insert some sample orders
INSERT INTO orders (user_id, product_name, quantity, price) VALUES
(1, 'Product A', 2, 19.99),
(1, 'Product B', 1, 29.99),
(2, 'Product C', 3, 15.50),
(3, 'Product A', 1, 19.99),
(4, 'Product D', 2, 45.75),
(5, 'Product B', 1, 29.99),
(2, 'Product E', 4, 9.99);

-- Create a view that joins users and orders
CREATE OR REPLACE VIEW user_orders AS
SELECT u.id, u.username, u.email, o.order_id, o.product_name, o.quantity, o.price, o.order_date
FROM users u
JOIN orders o ON u.id = o.user_id;




cat mysql-to-kafka-cdc.sql 
-- MySQL CDC Source
CREATE TABLE mysql_users_cdc (
    id INT,
    username STRING,
    email STRING,
    created_at TIMESTAMP(3),
    updated_at TIMESTAMP(3),
    PRIMARY KEY (id) NOT ENFORCED
) WITH (
    'connector' = 'mysql-cdc',
    'hostname' = 'mysql',
    'port' = '3306',
    'username' = 'testuser',
    'password' = 'testpassword',
    'database-name' = 'testdb',
    'table-name' = 'users',
    'server-time-zone' = 'UTC'
);

-- Kafka Sink
CREATE TABLE kafka_users_cdc (
    id INT PRIMARY KEY NOT ENFORCED,
    username STRING,
    email STRING,
    created_at TIMESTAMP(3),
    updated_at TIMESTAMP(3)
) WITH (
    'connector' = 'upsert-kafka',
    'topic' = 'my_topic',
    'properties.bootstrap.servers' = 'kafka:9092',
    'key.format' = 'json',
    'value.format' = 'json',
    'value.fields-include' = 'EXCEPT_KEY',
    'properties.auto.offset.reset' = 'earliest'
);

-- Pipeline
INSERT INTO kafka_users_cdc
SELECT * FROM mysql_users_cdc;


/conf# cat flink-conf.yaml 
# Flink Configuration
jobmanager.rpc.address: jobmanager
jobmanager.rpc.port: 6123
jobmanager.memory.process.size: 2048m
taskmanager.memory.process.size: 2048m
taskmanager.numberOfTaskSlots: 2
parallelism.default: 2
state.backend: filesystem
state.checkpoints.dir: file:///opt/flink/checkpoints
state.savepoints.dir: file:///opt/flink/savepoints
high-availability: zookeeper
high-availability.zookeeper.quorum: zookeeper:2181
high-availability.zookeeper.path.root: /flink
high-availability.cluster-id: /flink-cluster
high-availability.storageDir: file:///opt/flink/ha
restart-strategy: fixed-delay
restart-strategy.fixed-delay.attempts: 3
restart-strategy.fixed-delay.delay: 10s
blob.server.port: 6124
query.server.port: 6125
